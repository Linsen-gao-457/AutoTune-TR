{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOLEtOLTEZAGPK/FO0EWVhR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ryu1231/TR-vs-SGD/blob/main/Reproduce_TR_%26_SGD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "collapsed": true,
        "id": "uuscgpIKoX_Z"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Subset\n",
        "import time\n",
        "import pickle\n",
        "import os\n",
        "\n",
        "device = torch.device('cpu')\n",
        "def load_cifar10_data(subset_size=5000, seed=1234):\n",
        "    torch.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "\n",
        "    train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "    test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "    indices = torch.randperm(len(train_dataset))[:subset_size]\n",
        "    train_subset = Subset(train_dataset, indices)\n",
        "\n",
        "    X = torch.stack([img.flatten() for img, _ in train_subset]).t()\n",
        "    y = torch.zeros(len(train_subset), 10, device=device)\n",
        "    for i, (_, label) in enumerate(train_subset):\n",
        "        y[i, label] = 1\n",
        "\n",
        "    X_test = torch.stack([img.flatten() for img, _ in test_dataset]).t()\n",
        "    y_test = torch.zeros(len(test_dataset), 10, device=device)\n",
        "    for i, (_, label) in enumerate(test_dataset):\n",
        "        y_test[i, label] = 1\n",
        "\n",
        "    mean_data = X.mean(dim=1, keepdim=True)\n",
        "    std_data = X.std(dim=1, keepdim=True)\n",
        "    std_data[std_data == 0] = 1\n",
        "    X = (X - mean_data) / std_data\n",
        "    X_test = (X_test - mean_data) / std_data\n",
        "\n",
        "    return X.to(device), y, X_test.to(device), y_test\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(MLP, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x, apply_softmax=True):\n",
        "        z = [x]\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc1(x)\n",
        "        x = torch.sigmoid(x)\n",
        "        z.append(x)\n",
        "        x = self.fc2(x)\n",
        "        z.append(x)\n",
        "        if apply_softmax:\n",
        "            x = F.softmax(x, dim=1)\n",
        "        z.append(x)\n",
        "        return z\n",
        "\n",
        "def unflatten_parameters(model, params):\n",
        "    idx = 0\n",
        "    for p in model.parameters():\n",
        "        numel = p.numel()\n",
        "        p.data.copy_(params[idx:idx+numel].reshape(p.shape))\n",
        "        idx += numel\n",
        "\n",
        "def compute_model(model, params, X, y, lambda_reg=0, compute_hess=False):\n",
        "    n = X.size(1)\n",
        "    unflatten_parameters(model, params)\n",
        "\n",
        "    z = model(X.t())\n",
        "    outputs = z[-1]\n",
        "\n",
        "    ll = torch.sum(y * torch.log(outputs + 1e-10))\n",
        "    loss = -ll / n\n",
        "    perr = torch.mean((torch.argmax(y, dim=1) != torch.argmax(outputs, dim=1)).float())\n",
        "\n",
        "    reg_term = 0.5 * lambda_reg * torch.sum(params ** 2)\n",
        "    total_loss = loss + reg_term\n",
        "\n",
        "    model.zero_grad()\n",
        "    outputs = model(X.t())[-1]\n",
        "    ll = torch.sum(y * torch.log(outputs + 1e-10))\n",
        "    loss = -ll / n + reg_term\n",
        "    grad = torch.autograd.grad(loss, model.parameters(), create_graph=compute_hess)\n",
        "    grad_flat = torch.cat([g.flatten() for g in grad])\n",
        "\n",
        "    if not compute_hess:\n",
        "        return total_loss.item(), perr.item(), grad_flat\n",
        "\n",
        "    def hess(V):\n",
        "        model.zero_grad()\n",
        "        grad_v = torch.sum(grad_flat * V)\n",
        "        Hv = torch.autograd.grad(grad_v, model.parameters(), retain_graph=True)\n",
        "        Hv_flat = torch.cat([hv.flatten() for hv in Hv])\n",
        "        return Hv_flat + lambda_reg * V\n",
        "\n",
        "    return total_loss.item(), grad_flat, hess, perr.item()\n",
        "\n",
        "def cg_steihaug(H, g, delta, params, x0):\n",
        "    tr_model = lambda x: 0.5 * torch.dot(x, H(x)) + torch.dot(x, g)\n",
        "    errtol, maxit, _ = params\n",
        "    x = torch.zeros_like(g) if x0 is None else x0\n",
        "    r = -g - H(x)\n",
        "    z = r\n",
        "    rho = torch.dot(z, r)\n",
        "    tst = torch.norm(r)\n",
        "    terminate = errtol * torch.norm(r)\n",
        "    it = 0\n",
        "    hatdel = delta\n",
        "    rhoold = 1.0\n",
        "\n",
        "    if tst <= terminate:\n",
        "        return x, tr_model(x), 0, 'RS'\n",
        "\n",
        "    while (tst > terminate and it < maxit and torch.norm(x) <= hatdel):\n",
        "        if it == 0:\n",
        "            p = z\n",
        "        else:\n",
        "            beta = rho / rhoold\n",
        "            p = z + beta * p\n",
        "\n",
        "        w = H(p)\n",
        "        alpha = torch.dot(w, p)\n",
        "        if alpha <= 0:\n",
        "            ac = torch.dot(p, p)\n",
        "            bc = 2 * torch.dot(x, p)\n",
        "            cc = torch.dot(x, x) - delta * delta\n",
        "            discriminant = bc**2 - 4 * ac * cc\n",
        "            alpha = (-bc + torch.sqrt(discriminant)) / (2 * ac) if discriminant >= 0 else 0\n",
        "            x = x + alpha * p\n",
        "            return x, tr_model(x), it, 'NC'\n",
        "        else:\n",
        "            alpha = rho / alpha\n",
        "            if torch.norm(x + alpha * p) > delta:\n",
        "                ac = torch.dot(p, p)\n",
        "                bc = 2 * torch.dot(x, p)\n",
        "                cc = torch.dot(x, x) - delta * delta\n",
        "                discriminant = bc**2 - 4 * ac * cc\n",
        "                alpha = (-bc + torch.sqrt(discriminant)) / (2 * ac) if discriminant >= 0 else 0\n",
        "                x = x + alpha * p\n",
        "                return x, tr_model(x), it, 'TR'\n",
        "\n",
        "        x = x + alpha * p\n",
        "        r = r - alpha * w\n",
        "        tst = torch.norm(r)\n",
        "        if tst <= terminate:\n",
        "            return x, tr_model(x), it, 'RS'\n",
        "        if torch.norm(x) >= hatdel:\n",
        "            return x, tr_model(x), it, 'TR'\n",
        "\n",
        "        rhoold = rho\n",
        "        z = r\n",
        "        rho = torch.dot(z, r)\n",
        "        it += 1\n",
        "\n",
        "    return x, tr_model(x), it, 'MX'\n",
        "\n",
        "def subsampled_tr(model, X, y, X_test, y_test, lambda_reg, options):\n",
        "    n = X.size(1)\n",
        "    sz = int(0.05 * n)\n",
        "\n",
        "    delta = options.get('delta', 5)\n",
        "    eta1 = options.get('eta1', 0.8)\n",
        "    eta2 = options.get('eta2', 1e-4)\n",
        "    gamma1 = options.get('gamma1', 2)\n",
        "    gamma2 = options.get('gamma2', 1.2)\n",
        "    maxNoProps = options.get('maxNoProps', float('inf'))\n",
        "    max_iters = options.get('max_iters', 100)\n",
        "    inner_iters = options.get('inner_iters', 100)\n",
        "    cur = options.get('cur_iter', 0)\n",
        "    sz = options.get('hs', sz)\n",
        "\n",
        "    if cur >= 1:\n",
        "        noProps = options['tr_noProps'][cur]\n",
        "        tr_losses = options['tr_losses'][:cur] + [0] * max_iters\n",
        "        tr_noProps = options['tr_noProps'][:cur] + [0] * max_iters\n",
        "        te_errs = options['te_errs'][:cur] + [0] * max_iters\n",
        "    else:\n",
        "        noProps = 1\n",
        "        noMVPs = 1\n",
        "        tr_losses = [0] * max_iters\n",
        "        tr_noProps = [0] * max_iters\n",
        "        te_errs = [0] * max_iters\n",
        "\n",
        "    params = options.get('params')\n",
        "\n",
        "    print(\"\\nStart training...\\n\")\n",
        "    for iter in range(cur + 1, cur + max_iters + 1):\n",
        "        if noProps > maxNoProps:\n",
        "            iter -= 1\n",
        "            break\n",
        "\n",
        "        idx = torch.randperm(n)[:sz]\n",
        "        x_sample = X[:, idx]\n",
        "        y_sample = y[idx]\n",
        "\n",
        "        ll, tr_err, grad = compute_model(model, params, X, y, lambda_reg)\n",
        "        tr_loss = ll\n",
        "        grad = grad + lambda_reg * params\n",
        "        _, _, hess, _ = compute_model(model, params, x_sample, y_sample, lambda_reg, compute_hess=True)\n",
        "        HessV = lambda V: hess(V)\n",
        "        noProps += n\n",
        "\n",
        "        _, te_err, _ = compute_model(model, params, X_test, y_test, lambda_reg)\n",
        "\n",
        "        tr_losses[iter-1] = tr_loss\n",
        "        te_errs[iter-1] = te_err\n",
        "        tr_noProps[iter-1] = noProps\n",
        "\n",
        "        print(f\"Training loss: {tr_loss:.4f}\")\n",
        "        print(f\"Test Error: {te_err:.4f}\")\n",
        "\n",
        "        fail_count = 0\n",
        "        while True:\n",
        "            steihaugParams = [1e-9, 250, 0]\n",
        "            if fail_count == 0:\n",
        "                s0 = torch.randn_like(params)\n",
        "                s0 = 0.99 * delta * s0 / torch.norm(s0)\n",
        "            s, m, num_cg, iflag = cg_steihaug(HessV, grad, delta, steihaugParams, s0)\n",
        "            noProps += num_cg * 2 * x_sample.size(1)\n",
        "            noMVPs += num_cg\n",
        "\n",
        "            if m >= 0:\n",
        "                s = torch.zeros_like(s)\n",
        "                break\n",
        "\n",
        "            newll_err = compute_model(model, params + s, X, y, lambda_reg)\n",
        "            newll, _, _ = newll_err\n",
        "            noProps += n\n",
        "            newll = newll + 0.5 * lambda_reg * torch.norm(params + s) ** 2\n",
        "            rho = (tr_loss - newll) / -m if m != 0 else -float('inf')\n",
        "\n",
        "            if rho < eta2:\n",
        "                fail_count += 1\n",
        "                delta = delta / gamma1\n",
        "                s0 = delta * s / torch.norm(s)\n",
        "            elif rho < eta1:\n",
        "                params = params + s\n",
        "                delta = gamma2 * delta\n",
        "                break\n",
        "            else:\n",
        "                params = params + s\n",
        "                delta = gamma1 * delta\n",
        "                break\n",
        "\n",
        "    options = {\n",
        "        'params': params,\n",
        "        'cur_iter': iter,\n",
        "        'tr_losses': tr_losses[:iter],\n",
        "        'te_errs': te_errs[:iter],\n",
        "        'tr_noProps': tr_noProps[:iter],\n",
        "    }\n",
        "    return params, options\n",
        "\n",
        "def momentum_sgd(model, X, y, X_test, y_test, lambda_reg, options):\n",
        "    n = X.size(1)\n",
        "    sz = int(0.05 * n)\n",
        "\n",
        "    alpha = options.get('alpha', 0.005)\n",
        "    beta = options.get('beta', 0.9)\n",
        "    maxNoProps = options.get('maxNoProps', float('inf'))\n",
        "    max_iters = options.get('max_iters', 100)\n",
        "    cur = options.get('cur_iter', 0)\n",
        "    sz = options.get('hs', sz)\n",
        "\n",
        "    if cur >= 1:\n",
        "        noProps = options['tr_noProps'][cur]\n",
        "        tr_losses = options['tr_losses'][:cur] + [0] * max_iters\n",
        "        tr_noProps = options['tr_noProps'][:cur] + [0] * max_iters\n",
        "        te_errs = options['te_errs'][:cur] + [0] * max_iters\n",
        "    else:\n",
        "        noProps = 1\n",
        "        tr_losses = [0] * max_iters\n",
        "        tr_noProps = [0] * max_iters\n",
        "        te_errs = [0] * max_iters\n",
        "\n",
        "    params = options.get('params')\n",
        "\n",
        "    print(\"\\nStart training...\\n\")\n",
        "    momentum_params = torch.zeros_like(params)\n",
        "    for iter in range(cur + 1, cur + max_iters + 1):\n",
        "        if noProps > maxNoProps:\n",
        "            iter -= 1\n",
        "            break\n",
        "\n",
        "        idx = torch.randperm(n)[:sz]\n",
        "        x_sample = X[:, idx]\n",
        "        y_sample = y[idx]\n",
        "\n",
        "        _, _, grad = compute_model(model, params, x_sample, y_sample, lambda_reg)\n",
        "        grad = grad + lambda_reg * params\n",
        "        noProps += 2 * x_sample.size(1)\n",
        "\n",
        "        ll, tr_err, _ = compute_model(model, params, X, y, lambda_reg)\n",
        "        tr_loss = ll\n",
        "\n",
        "        _, te_err, _ = compute_model(model, params, X_test, y_test, lambda_reg)\n",
        "\n",
        "        tr_losses[iter-1] = tr_loss\n",
        "        te_errs[iter-1] = te_err\n",
        "        tr_noProps[iter-1] = noProps\n",
        "\n",
        "        print(f\"Training loss: {tr_loss:.4f}\")\n",
        "        print(f\"Test Error: {te_err:.4f}\")\n",
        "\n",
        "        momentum_params = beta * momentum_params - alpha * grad\n",
        "        params = params + momentum_params\n",
        "\n",
        "    options = {\n",
        "        'params': params,\n",
        "        'cur_iter': iter,\n",
        "        'tr_losses': tr_losses[:iter],\n",
        "        'te_errs': te_errs[:iter],\n",
        "        'tr_noProps': tr_noProps[:iter],\n",
        "    }\n",
        "    return params, options\n",
        "\n",
        "def cifar_classification(method, hs_sub=0.05, delta=1000, alpha=0.05, init=0, maxNP=1e6, seed=1234):\n",
        "    torch.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    X, y, X_test, y_test = load_cifar10_data(subset_size=5000, seed=seed)\n",
        "\n",
        "    input_size = 32 * 32 * 3\n",
        "    hidden_size = 512\n",
        "    num_classes = 10\n",
        "    model = MLP(input_size, hidden_size, num_classes).to(device)\n",
        "    psize = sum(p.numel() for p in model.parameters())\n",
        "    lambda_reg = 0\n",
        "\n",
        "    if init == 0:\n",
        "        initial_guess = torch.zeros(psize, device=device)\n",
        "        print(\"Zero Initialization\")\n",
        "    else:\n",
        "        initial_guess = torch.randn(psize, device=device)\n",
        "        initial_guess = initial_guess / torch.norm(initial_guess)\n",
        "        print(\"Normalized Random Initialization\")\n",
        "\n",
        "    options = {\n",
        "        'params': initial_guess,\n",
        "        'name': 'cifar10_classification',\n",
        "        'inner_iters': 250,\n",
        "        'alpha': alpha,\n",
        "        'delta': delta,\n",
        "        'max_iters': 500,\n",
        "        'cur_iter': 0,\n",
        "        'hs': int(hs_sub * X.size(1)),\n",
        "        'maxNoProps': maxNP\n",
        "    }\n",
        "\n",
        "    if method == 'TR':\n",
        "        params, options = subsampled_tr(model, X, y, X_test, y_test, lambda_reg, options)\n",
        "    elif method == 'SGD':\n",
        "        params, options = momentum_sgd(model, X, y, X_test, y_test, lambda_reg, options)\n",
        "    return options"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Initialization"
      ],
      "metadata": {
        "id": "VTSo5xZB94oQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TR"
      ],
      "metadata": {
        "id": "NPkOQsvD92hy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "delta_list = [10, 100]\n",
        "maxNP = 1e6\n",
        "tr_results = []\n",
        "for delta in delta_list:\n",
        "    print(f\"Running TR with delta={delta}\")\n",
        "    options = cifar_classification('TR', hs_sub=0.05, delta=delta, init=1, maxNP=maxNP, seed=1234)\n",
        "    tr_results.append(options)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "PELAOgrr1WjG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SGD"
      ],
      "metadata": {
        "id": "eyBK9HLtCJ5S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "alpha_list = [0.05, 0.2]\n",
        "maxNP = 1e6\n",
        "sgd_results = []\n",
        "for alpha in alpha_list:\n",
        "    print(f\"Running SGD with alpha={alpha}\")\n",
        "    options = cifar_classification('SGD', hs_sub=0.05, alpha=alpha, init=1, maxNP=maxNP, seed=1234)\n",
        "    sgd_results.append(options)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "OypgIsUjB2JO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot"
      ],
      "metadata": {
        "id": "zgBjon6L_6ZY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "colors_tr = ['blue', 'purple']\n",
        "colors_sgd = ['green', 'red', 'organce']\n",
        "for i, (results, delta) in enumerate(zip(tr_results, delta_list)):\n",
        "    plt.plot(results['tr_noProps'], results['tr_losses'], label=f'TR-CG: Δ0={delta}', color=colors_tr[i])\n",
        "for i, (results, alpha) in enumerate(zip(sgd_results, alpha_list)):\n",
        "    plt.plot(results['tr_noProps'], results['tr_losses'], label=f'SGD: α={alpha}', color=colors_sgd[i], linestyle='--')\n",
        "plt.xscale('log')\n",
        "plt.yscale('log')\n",
        "plt.xlabel('# of Props')\n",
        "plt.ylabel('Training Loss')\n",
        "plt.title('Image Classification: CIFAR-10 (Random Init)')\n",
        "plt.legend()\n",
        "plt.grid(True, which=\"both\", ls=\"--\")\n",
        "plt.savefig('figure_a.png')\n",
        "plt.show()\n",
        "plt.close()\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "for i, (results, delta) in enumerate(zip(tr_results, delta_list)):\n",
        "    plt.plot(results['tr_noProps'], results['te_errs'], label=f'TR-CG: Δ0={delta}', color=colors_tr[i])\n",
        "for i, (results, alpha) in enumerate(zip(sgd_results, alpha_list)):\n",
        "    plt.plot(results['tr_noProps'], results['te_errs'], label=f'SGD: α={alpha}', color=colors_sgd[i], linestyle='--')\n",
        "plt.xscale('log')\n",
        "plt.xlabel('# of Props')\n",
        "plt.ylabel('Test Error')\n",
        "plt.title('Image Classification: CIFAR-10 (Random Init)')\n",
        "plt.legend()\n",
        "plt.grid(True, which=\"both\", ls=\"--\")\n",
        "plt.savefig('figure_c.png')\n",
        "plt.show()\n",
        "plt.close()"
      ],
      "metadata": {
        "id": "3aOjFGkH8S9e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Saddle Point Initialization"
      ],
      "metadata": {
        "id": "x2hcXP9VHTSW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TR"
      ],
      "metadata": {
        "id": "kaCfA481HY5A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "maxNP = 1e5\n",
        "print(f\"Running TR with delta={delta}\")\n",
        "tr_zero = cifar_classification('TR', hs_sub=0.05, delta=1, init=0, maxNP=maxNP, seed=1234)"
      ],
      "metadata": {
        "id": "6jYO2I22_zGi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SGD"
      ],
      "metadata": {
        "id": "ZB3PeHkQHaVV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "maxNP = 1e5\n",
        "alpha = 0.01\n",
        "print(f\"Running SGD with alpha={alpha}\")\n",
        "sgd_zero = cifar_classification('SGD', hs_sub=0.05, alpha=alpha, init=0, maxNP=maxNP, seed=1234)"
      ],
      "metadata": {
        "id": "7fsfsO_x_0Lc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot"
      ],
      "metadata": {
        "id": "rAG8XLTC_-h9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(tr_zero['tr_noProps'], tr_zero['tr_losses'], label=f'TR-CG: Δ={delta}', color='blue')\n",
        "plt.plot(sgd_zero['tr_noProps'], sgd_zero['tr_losses'], label=f'SGD: α={alpha}', color='orange', linestyle='--')\n",
        "plt.xscale('log')\n",
        "plt.yscale('log')\n",
        "plt.xlabel('# of Props')\n",
        "plt.ylabel('Training Loss')\n",
        "plt.title('Image Classification: CIFAR-10 (Saddle Point Init)')\n",
        "plt.legend()\n",
        "plt.grid(True, which=\"both\", ls=\"--\")\n",
        "plt.savefig('figure_d.png')\n",
        "plt.show()\n",
        "plt.close()\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(tr_zero['tr_noProps'], tr_zero['te_errs'], label=f'TR-CG: Δ={delta}', color='blue')\n",
        "plt.plot(sgd_zero['tr_noProps'], sgd_zero['te_errs'], label=f'SGD: α={alpha}', color='orange', linestyle='--')\n",
        "plt.xscale('log')\n",
        "plt.xlabel('# of Props')\n",
        "plt.ylabel('Test Error')\n",
        "plt.title('Image Classification: CIFAR-10 (Saddle Point Init)')\n",
        "plt.legend()\n",
        "plt.grid(True, which=\"both\", ls=\"--\")\n",
        "plt.savefig('figure_f.png')\n",
        "plt.show()\n",
        "plt.close()"
      ],
      "metadata": {
        "id": "bZvBvfWHAAbc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}